---
title: "ANÁLISIS AVANZADO DE DATOS - Taller 2"
author: "Raúl Andrés Rodriguez - Richard Felipe Bolaños"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerías

```{r}
library(ISLR2)
library(splines)
library(boot)

```

## Dataset

Se realiza una exploración básica del dataset autos.

```{r}
#Cargar los datos
df <- data.frame(Auto)

#Explorar 5 filas del conjunto de datos
head(df, 5)
```

```{r}
#Exporación basica del conjunto de datos
summary(df[c(1,4)])
```

## Problema \# 1

El conjunto de datos Auto en la librería ISLR2, utilizado en clase,
contiene la información del rendimiento y otras variables para un total
de 392 vehículos. Como nos dimos cuenta, la relación entre dos de sus
variables (horsepower y mpg) es resumida de manera parsimoniosa mediante
un polinomio global de grado 2, sin embargo un spline suavizado
(smoothing spline) parece dar un menor error de predicción. Por otra
parte, determinar la ubicación y cantidad de knots en el spline de
regresión (regression spline) fue un problema que desincentivó su uso.
El método de validación externa utilizado para comprar los modelos fue
validación regular.

### Punto No 1.

Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en
dos partes:

-   Entrenamiento: 90 % de los autos.

-   Prueba: 10 % de los autos.

```{r}
# Establecer la semilla para reproducibilidad
set.seed(12)

#Se genera un vector ind de longitud igual al número de filas de df. Cada elemento de ind es una muestra aleatoria de tamaño 1 de los números 1 y 2, con una probabilidad de selección especificada por el vector prob.
ind <- sample(2, nrow(df), replace = TRUE, prob = c(0.9, 0.1))

#Aquí se seleccionan las filas de df donde ind es igual a 1, generando el conjunto de entrenamiento
df_train <- df[ind == 1, ]

#Aquí se seleccionan las filas de df donde ind es igual a 2, generando el conjunto de prueba
df_test <- df[ind == 2, ] 

```

### Punto No 2.

**Usando los datos de entrenamiento** Mediante validación cruzada en 10
folds, determine el número óptimo de knots para el problema de regresión
spline. Considere como número de posible de knots 1,...,10, igualmente
espaciados en el rango de la variable horsepower. ¿Qué modelo (es decir,
cual valor de knot con k = 1, ..., 10) resulta en un menor ECM de
predición?

```{r}
set.seed(12)
data1 <- df_train[, c("horsepower", "mpg")]
cv.error.10 <- NULL


for (i in 1:10) {
  glm.fit <- glm(mpg ~ bs(horsepower,knots=i,  df = 3), data = data1)

  cv.error.10[i] <- cv.glm(data1,glm.fit,K = 10)$delta[1]

  print(cv.error.10[i])

  print(paste0("knot =", i, ", ECM CV =", cv.error.10[i]))
}

# Encuentra el número óptimo de knots con el menor ECM
optimal_knots <- which.min(cv.error.10)

cat("El número óptimo de knots es:", optimal_knots, "\n")
cat("El ECM mínimo es:", min(cv.error.10), "\n")


```

### Punto No 3.

**Usando los datos de entrenamiento, determine el mejor modelo basado en
base de funciones** Compare el poder de predicción de los modelos:
polinomio grado 2 global, spline suavizado y del modelo de regresión
spline óptimo (encontrado en el punto anterior) utilizando validación
cruzada en 10 folds. ¿Cuál de los tres modelos seleccionaría basado en
el ECM de predición?

```{r}

# Establecer la semilla
set.seed(12)

# Seleccionar datos
data <- df_train[, c("horsepower", "mpg")]

# Inicializar vector para almacenar los errores
cv.error.10 <- NULL

# Número de folds para la validación cruzada
num_folds <- 10



# -----------Polinomnio grado 2-----------
glm.fit <- glm (mpg ~ poly (horsepower , 2), data = df_train)
cv.error.10 <- cv.glm(df_train,glm.fit,K = num_folds)$delta[1]

cat("El ECM del modelo polinomio grado 2 es:", cv.error.10, "\n")




# -----------Spline suavizado-----------
# División de los datos en folds
fold_indices <- sample(rep(1:num_folds, length.out = nrow(data)))

# Realizar la validación cruzada
for (i in 1:num_folds) {
    # Divide los datos en conjunto de entrenamiento y prueba
    test_indices <- which(fold_indices == i)
    train_data <- data[-test_indices, ]
    test_data <- data[test_indices, ]
  
    # Ajustar smooth.spline en el conjunto de entrenamiento
    spline_fit<-smooth.spline(train_data$horsepower,train_data$mpg)
  
    # Predecir en el conjunto de prueba
    predicted <- predict(spline_fit, test_data$horsepower)$y
  
    # Calcular el error cuadrático medio (ECM)
    cv.error.10[i] <- mean((test_data$mpg - predicted)^2)
}
# Imprime los resultados
cat("El ECM del modelo spline suavizado es:", mean(cv.error.10), "\n")






```

### Punto No 4.

Usando los datos de entrenamiento, determine el mejor modelo basado en
regresión local Determine la regresión polinomial local con kernel
gaussiano que resulte en menor error de predicción: regresión de grado 1
o 2. Use el ancho de banda óptimo dado por defecto por la función
loess().

```{r}

```

### Punto No 5.

Usando los datos de entrenamiento y de prueba, determine el mejor de los
tres paradigmas de modelamiento Ajuste el mejor modelo basado en base de
funciones, el mejor modelo basado en regresión local y un polinomio
global de grado dos con los datos de entrenamiento y calcule el ECM de
prueba para cada modelo.

```{r}

```

### Punto No 6.

Repita (1) - (5) un total de 10 veces de manera que en el paso (1)
conforme una nueva muestra de validación cruzada, esto le permitirá
obtener 10 ECM de prueba para cada paradigma de modelamiento. Grafique
las tres distribuciones del ECM de prueba y responda ¿Cuál acercamiento
seleccionaría basado en el ECM de predición: basado en base de
funciones, basado en regresión local o polinomial global?

```{r}

```

## Problema \# 2

En el contexto de análisis de datos funcionales se tiene una colección
finita de observaciones ruidosas, donde para cada individuo, estas se
asumen provenientes de una curva de dimensión infinita la cual es
evaluada en puntos de un intervalo determinado. Para la i-ésima unidad
estadística se tiene un conjunto de ni observaciones discretizadas xi1,
..., xij , ..., xin de la función xi en los puntos ti1, ..., tij , ...,
tin con xij ∈ R, tij ∈ T y T un intervalo que representa el dominio
sobre los reales donde se definen los datos funcionales.

### Punto No 7.

Escriba el estimador de Nadarya–Watson para la i-ésima unidad
estadística en t, es decir, x(t).

```{r}

```

### Punto No 8.

Escriba el estimador de Nadarya–Watson para la función media en t, es
decir, ˆµ(t).

```{r}

```
