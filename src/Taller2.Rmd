---
title: "ANÁLISIS AVANZADO DE DATOS - Taller 2"
author: "Raúl Andrés Rodriguez - Richard Felipe Bolaños"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)

```

## Librerías

```{r, warning = FALSE }

# Cargar las librerias a utilizar
library(ISLR2)
library(splines)
library(boot)

```

## Dataset

Se realiza una exploración básica del dataset autos.

```{r}
#Cargar los datos
df <- data.frame(Auto)

#Explorar 5 filas del conjunto de datos
head(df, 5)
```

```{r}
#Exporación basica del conjunto de datos
summary(df[c(1,4)])
```

## Problema \# 1

El conjunto de datos Auto en la librería ISLR2, utilizado en clase,
contiene la información del rendimiento y otras variables para un total
de 392 vehículos. Como nos dimos cuenta, la relación entre dos de sus
variables (horsepower y mpg) es resumida de manera parsimoniosa mediante
un polinomio global de grado 2, sin embargo un spline suavizado
(smoothing spline) parece dar un menor error de predicción. Por otra
parte, determinar la ubicación y cantidad de knots en el spline de
regresión (regression spline) fue un problema que desincentivó su uso.
El método de validación externa utilizado para comprar los modelos fue
validación regular.

### Punto No 1.

Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en
dos partes:

-   Entrenamiento: 90 % de los autos.

-   Prueba: 10 % de los autos.

```{r}

# Establecer la semilla para reproducibilidad
set.seed(12)

# Generar un vector ind de longitud igual al número de filas de df. Cada elemento de ind es una muestra aleatoria de tamaño 1 de los números 1 y 2, con una probabilidad de selección especificada por el vector prob.
ind <- sample(2, nrow(df), replace = TRUE, prob = c(0.9, 0.1))

# Seleccionar las filas de df donde ind es igual a 1, generando el conjunto de entrenamiento
df_train <- df[ind == 1, ]

sprintf ("Tamaño conjunto de entrenamiento: %d", nrow(df_train))

# Seleccionan las filas de df donde ind es igual a 2, generando el conjunto de prueba
df_test <- df[ind == 2, ] 

sprintf ("Tamaño conjunto de prueba: %d", nrow(df_test))


```

### Punto No 2.

**Usando los datos de entrenamiento** Mediante validación cruzada en 10
folds, determine el número óptimo de knots para el problema de regresión
spline. Considere como número de posible de knots 1,...,10, igualmente
espaciados en el rango de la variable horsepower. ¿Qué modelo (es decir,
cual valor de knot con k = 1, ..., 10) resulta en un menor ECM de
predición?

```{r warning = FALSE}

# Establecer la semilla para reproducibilidad
set.seed(12)

# Definir variables
data1 <- df_train[, c("horsepower", "mpg")]
cv.error.10 <- NULL

# Establecer ciclo para los 10 nkots y el cross-validation
for (i in 1:10) {
  glm.fit <- glm(mpg ~ bs(horsepower,knots=i,  df = 3), data = data1)
  cv.error.10[i] <- cv.glm(data1,glm.fit,K = 10)$delta[1]

  print(paste0("knot =", i, ", ECM CV =", cv.error.10[i]))
}

# Encontrar el número óptimo de knots con el menor ECM
optimal_knots <- which.min(cv.error.10)

# Encontrar el número óptimo de knots con el menor ECM
cat("El número óptimo de knots es:", optimal_knots, "\n")
cat("El ECM mínimo es:", ECMRS<-min(cv.error.10), "\n")
```

### Punto No 3.

**Usando los datos de entrenamiento, determine el mejor modelo basado en
base de funciones** Compare el poder de predicción de los modelos:
polinomio grado 2 global, spline suavizado y del modelo de regresión
spline óptimo (encontrado en el punto anterior) utilizando validación
cruzada en 10 folds. ¿Cuál de los tres modelos seleccionaría basado en
el ECM de predición?

```{r}

# Establecer la semilla para reproducibilidad
set.seed(12)

# Seleccionar datos
data <- df_train[, c("horsepower", "mpg")]

# Mostrar el ECM del modelo del punto # 2
cat("El ECM del modelo regresion spline es:", ECMRS, "\n")


# Inicializar vector para almacenar los errores
cv.error.10 <- NULL

# Número de folds para la validación cruzada
num_folds <- 10


# -----------Polinomnio grado 2-----------
glm.fit <- glm (mpg ~ poly (horsepower , 2), data = df_train)
cv.error.10 <- cv.glm(df_train,glm.fit,K = num_folds)$delta[1]

cat("El ECM del modelo polinomio grado 2 es:", cv.error.10, "\n")


# Inicializar vector para almacenar los errores
cv.error.10 <- NULL

# -----------Spline suavizado-----------
#NOTA: Se ejecuta con en numero optimo de Knots del punto # 2
# División de los datos en folds
fold_indices <- sample(rep(1:num_folds, length.out = nrow(data)))

# Realizar la validación cruzada
for (i in 1:num_folds) {
    # Divide los datos en conjunto de entrenamiento y prueba
    test_indices <- which(fold_indices == i)
    train_data <- data[-test_indices, ]
    test_data <- data[test_indices, ]
  
    # Ajustar smooth.spline en el conjunto de entrenamiento
    spline_fit<-smooth.spline(train_data$horsepower,train_data$mpg,nknots=optimal_knots)
  
    # Predecir en el conjunto de prueba
    predicted <- predict(spline_fit, test_data$horsepower)$y
  
    # Calcular el error cuadrático medio (ECM)
    cv.error.10[i] <- mean((test_data$mpg - predicted)^2)
}
# Imprime los resultados
cat("El ECM del modelo spline suavizado es:", mean(cv.error.10), "\n")

```

### Punto No 4.

Usando los datos de entrenamiento, determine el mejor modelo basado en
regresión local Determine la regresión polinomial local con kernel
gaussiano que resulte en menor error de predicción: regresión de grado 1
o 2. Use el ancho de banda óptimo dado por defecto por la función
loess().

```{r}

# Establecer la semilla para reproducibilidad
set.seed(12)

# Seleccionar datos
data <- df_train[, c("horsepower", "mpg")]


# Ajusta un modelo LOESS con ancho de banda óptimo
model_loess_1 <- loess(mpg ~ horsepower, data = data, degree = 1)
model_loess_2 <- loess(mpg ~ horsepower, data = data, degree = 2)

# Calcula los errores de predicción para ambos modelos
predictions_1 <- predict(model_loess_1, newdata = data)
predictions_2 <- predict(model_loess_2, newdata = data)

error_1 <- sum((data$mpg - predictions_1)^2)
error_2 <- sum((data$mpg - predictions_2)^2)

# Compara los errores y selecciona el mejor modelo
if (error_1 < error_2) {
  best_model <- model_loess_1
  best_degree <- 1
} else {
  best_model <- model_loess_2
  best_degree <- 2
}

# Visualiza los resultados
plot(data$horsepower, data$mpg, main = "Regresión Polinomial Local (LOESS)", xlab = "x", ylab = "y")
lines(data$horsepower, predict(best_model), col = "red", lwd = 2)
legend("topright", legend = paste("Grado", best_degree), col = "red", lwd = 2)

```

### Punto No 5.

Usando los datos de entrenamiento y de prueba, determine el mejor de los
tres paradigmas de modelamiento Ajuste el mejor modelo basado en base de
funciones, el mejor modelo basado en regresión local y un polinomio
global de grado dos con los datos de entrenamiento y calcule el ECM de
prueba para cada modelo.

```{r, warning=FALSE}


# Definir variables
dataTr <- df_train[, c("horsepower", "mpg")]
dataTe <- df_test[, c("horsepower", "mpg")]

#---- Modelo basado en base de funciones
model_spline <- glm(mpg ~ bs(horsepower,knots=8, df = 3), data = dataTr)
predictions <- predict(model_spline, newdata = dataTe)
residuals <- dataTe$mpg - predictions
# Calcula el Error Cuadrático Medio (ECM)
MSE <- mean(residuals^2)
# Imprime el resultado
cat("Modelo en base de funciones: Error Cuadrático Medio (ECM) es:", MSE, "\n")  

#----Modelo basado en regresion local
model_loess <- loess(mpg ~ horsepower, data = dataTr, degree = 2)
predictions <- predict(model_loess, newdata = dataTe)
residuals <- dataTe$mpg - predictions
# Calcula el Error Cuadrático Medio (ECM)
MSE <- mean(residuals^2)
# Imprime el resultado
cat("Modelo regresion local: Error Cuadrático Medio (ECM) es:", MSE, "\n")  

#---- Polinomio global de grado dos
model_poly2 <- glm (mpg ~ poly (horsepower , 2), data = dataTr)
predictions <- predict(model_poly2, newdata = dataTe)
residuals <- dataTe$mpg - predictions
# Calcula el Error Cuadrático Medio (ECM)
MSE <- mean(residuals^2)
# Imprime el resultado
cat("Polinomio global grado 2: Error Cuadrático Medio (ECM) es:", MSE, "\n")  


```

### Punto No 6.

Repita (1) - (5) un total de 10 veces de manera que en el paso (1)
conforme una nueva muestra de validación cruzada, esto le permitirá
obtener 10 ECM de prueba para cada paradigma de modelamiento. Grafique
las tres distribuciones del ECM de prueba y responda ¿Cuál acercamiento
seleccionaría basado en el ECM de predición: basado en base de
funciones, basado en regresión local o polinomial global?

```{r}

# Generar datos de ejemplo
set.seed(12)
x <- df[, c("horsepower")]
y <- df[, c("mpg")]

# Número de iteraciones de validación cruzada
n_iter <- 10

# Función para calcular ECM
calc_ecm <- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}

# Función para realizar validación cruzada y obtener ECM
cross_validate <- function(model, x, y, n_iter) {
  ecm <- numeric(n_iter)
  for (i in 1:n_iter) {
    # Dividir datos en conjuntos de entrenamiento y validación
    idx <- sample(length(x), length(x), replace = FALSE)
    x_train <- x[idx[-1]]
    y_train <- y[idx[-1]]
    x_valid <- x[idx[1]]
    y_valid <- y[idx[1]]
    
    # Ajustar el modelo a los datos de entrenamiento
    fit <- model(x_train, y_train)
    
    # Predecir con el modelo ajustado en los datos de validación
    y_pred <- predict(fit, newdata = data.frame(x = x_valid))
    
    # Calcular ECM para esta iteración
    ecm[i] <- calc_ecm(y_valid, y_pred)
  }
  return(ecm)
}

# Ajustar modelo de regresión spline
spline_model <- function(x, y) glm(y ~ bs(x, knots=8,  df = 3),data = df)

# Ajustar modelo de regresión polinomial de grado 2
poly_model <- function(x, y) glm(y ~ poly(x, 2),data=df)

# Ajustar modelo LOESS
loess_model <- function(x, y) loess(y ~ x,data=df, degree=2)


# Realizar validación cruzada para cada modelo
spline_ecm <- cross_validate(spline_model, x, y, n_iter)
poly_ecm <- cross_validate(poly_model, x, y, n_iter)
loess_ecm <- cross_validate(loess_model, x, y, n_iter)

# Graficar distribuciones de ECM
par(mfrow = c(1, 3))
hist(spline_ecm, main = "Regresión Spline", xlab = "ECM", col = "skyblue")
hist(poly_ecm, main = "Regresión Polinomial de Grado 2", xlab = "ECM", col = "salmon")
hist(loess_ecm, main = "Regresión LOESS", xlab = "ECM", col = "lightgreen")

# Imprimir resumen de ECM
cat("ECM promedio (spline):", mean(spline_ecm), "\n")
cat("ECM promedio (polinomial):", mean(poly_ecm), "\n")
cat("ECM promedio (LOESS):", mean(loess_ecm), "\n")
```

## Problema \# 2

En el contexto de análisis de datos funcionales se tiene una colección
finita de observaciones ruidosas, donde para cada individuo, estas se
asumen provenientes de una curva de dimensión infinita la cual es
evaluada en puntos de un intervalo determinado. Para la i-ésima unidad
estadística se tiene un conjunto de ni observaciones discretizadas xi1,
..., xij , ..., xin de la función xi en los puntos ti1, ..., tij , ...,
tin con xij ∈ R, tij ∈ T y T un intervalo que representa el dominio
sobre los reales donde se definen los datos funcionales.

### Punto No 7.

Escriba el estimador de Nadarya–Watson para la i-ésima unidad
estadística en t, es decir, x(t).

$$\hat{x}_i(t) = \frac{\frac{1}{n} \sum_{j=1}^{n_i} K \left( \frac{t_{ini} - t}{h} \right) x_{ij}}{\frac{1}{n} \sum_{j=1}^{n_i} K \left( \frac{t_{ini} - t}{h} \right)}$$

### Punto No 8.

Escriba el estimador de Nadarya–Watson para la función media en t, es
decir, ˆµ(t).

$$\hat{\mu}(t) = \frac{1}{N} \sum_{i=1}^{k} \frac{  \frac{1}{N_k}  \sum_{j=1}^{n_{ik}} K \left( \frac{t_{inik} - t_k}{h_k} \right) x_{ijk}}{ \frac{1}{N_k}   \sum_{j=1}^{n_{ik}} K \left( \frac{t_{inik} - t_k}{h_k} \right)}
  $$
